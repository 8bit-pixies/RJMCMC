{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes Factor\n",
    "======\n",
    "\n",
    "This notebook will play around with \"estimating\" Bayes Factor for GMM using BIC. \n",
    "\n",
    "We use estimating very loosely as using BIC for BF means using a uniform prior!\n",
    "\n",
    "Using Formulation from (Wagenmakers 2007 p796): http://www.ejwagenmakers.com/2007/pValueProblems.pdf\n",
    "\n",
    "$$BF_{01} = \\frac{P(D|H_0)}{P(D|H_1)} = \\exp\\bigg(\\frac{\\text{BIC}(H_1) - \\text{BIC}(H_0)}{2}\\bigg) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from scipy import linalg\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import mixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we only take the first two features.\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = np.hstack([X.copy(), np.atleast_2d(X[:, 1]+1).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lik_mc(X, gmm_config={'n_components_range': range(1, 7), \n",
    "                 'cv_types': ['spherical', 'tied', 'diag', 'full']}):\n",
    "    # based on code here: \n",
    "    # http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_selection.html\n",
    "    \n",
    "    search_range = max(int(np.sqrt(X.shape[1])), 4)\n",
    "    n_components_range = range(1, search_range)\n",
    "    n_components_range = gmm_config['n_components_range']\n",
    "    \n",
    "    \n",
    "    cv_types = gmm_config['cv_types']\n",
    "    lowest_bic = np.infty\n",
    "    lik = []\n",
    "    \n",
    "    \n",
    "    for cv_type in cv_types:\n",
    "        for n_components in n_components_range:\n",
    "            # Fit a Gaussian mixture with EM\n",
    "            gmm = mixture.GaussianMixture(n_components=n_components,\n",
    "                                          covariance_type=cv_type)\n",
    "            gmm.fit(X)\n",
    "            # score gives the average log likelihood\n",
    "            likelihood = np.exp(gmm.score(X))\n",
    "            lik.append(likelihood)\n",
    "    return np.mean(lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lik_bayesfactor(lik0, lik1):\n",
    "    # will calculate: P(D|H_0)/P(D|H_1) \n",
    "    #\n",
    "    # from : https://mailman.ucsd.edu/pipermail/ling-r-lang-l/2013-December/000581.html\n",
    "    # The BIC approximation to the Bayes Factor he advocates for BF_01 is given by exp( (BIC_1 - BIC_0)/2 ) (see page 796).\n",
    "    # http://www.ejwagenmakers.com/2007/pValueProblems.pdf\n",
    "    return lik0/lik1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approx_bayesfactor(X0, X1, gmm_config={'n_components_range': range(1, 7), \n",
    "                 'cv_types': ['spherical', 'tied', 'diag', 'full']}):\n",
    "    lik0 = lik_mc(X0, gmm_config)\n",
    "    lik1 = lik_mc(X1, gmm_config)\n",
    "    \n",
    "    return lik_bayesfactor(lik0, lik1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0051804078848482274"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_bayesfactor(X, X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmm_config={'n_components_range': range(1, 7), \n",
    "                 'cv_types': ['spherical', 'tied', 'diag', 'full']}\n",
    "bic0 = lik_mc(X, gmm_config)\n",
    "bic1 = lik_mc(X1, gmm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16999715563203691"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bic0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.890812446795668"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
