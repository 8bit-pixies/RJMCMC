{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes Factor\n",
    "======\n",
    "\n",
    "This notebook will play around with \"estimating\" Bayes Factor for GMM using BIC. \n",
    "\n",
    "We use estimating very loosely as using BIC for BF means using a uniform prior!\n",
    "\n",
    "Using Formulation from (Wagenmakers 2007 p796): http://www.ejwagenmakers.com/2007/pValueProblems.pdf\n",
    "\n",
    "$$BF_{01} = \\frac{P(D|H_0)}{P(D|H_1)} = \\exp\\bigg(\\frac{\\text{BIC}(H_1) - \\text{BIC}(H_0)}{2}\\bigg) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from scipy import linalg\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import mixture\n",
    "from skfeature.function.similarity_based import SPEC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from functools import partial\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_features=100, n_informative=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = X[:, :80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lik_mc(X, top_n=None):\n",
    "    # based on code here: \n",
    "    # http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_selection.html\n",
    "    \n",
    "    search_range = max(int(np.sqrt(X.shape[1])), 4)\n",
    "    if top_n is None:\n",
    "        top_n = search_range\n",
    "    \n",
    "    n_components_range = range(1, search_range)\n",
    "    \n",
    "    lowest_bic = np.infty\n",
    "    lik = []\n",
    "    pipeline = []\n",
    "    kwargs = {'style': 0}\n",
    "    spec_partial = partial(SPEC.spec, **kwargs)\n",
    "    pipeline.append(('select top k', SelectKBest(score_func=spec_partial, k=top_n)))\n",
    "    model = Pipeline(pipeline)\n",
    "    \n",
    "    X_sel = model.fit_transform(X, y=np.zeros(X.shape[0]))\n",
    "    print(X_sel.shape)\n",
    "    \n",
    "    \n",
    "    for n_components in n_components_range:\n",
    "        # Fit a Gaussian mixture with EM\n",
    "        gmm = mixture.GaussianMixture(n_components=n_components)\n",
    "        gmm.fit(X_sel)\n",
    "        # score gives the average log likelihood\n",
    "        likelihood = np.exp(gmm.score(X_sel))\n",
    "        lik.append(likelihood)\n",
    "    # or with np.mean..\n",
    "    # this uses harmonic mean\n",
    "    return stats.hmean(lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lik_bayesfactor(lik0, lik1):\n",
    "    # will calculate: P(D|H_0)/P(D|H_1) \n",
    "    #\n",
    "    # from : https://mailman.ucsd.edu/pipermail/ling-r-lang-l/2013-December/000581.html\n",
    "    # The BIC approximation to the Bayes Factor he advocates for BF_01 is given by exp( (BIC_1 - BIC_0)/2 ) (see page 796).\n",
    "    # http://www.ejwagenmakers.com/2007/pValueProblems.pdf\n",
    "    return lik0/lik1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approx_bayesfactor(X0, X1, k=None):\n",
    "    lik0 = lik_mc(X0, k)\n",
    "    lik1 = lik_mc(X1, k)\n",
    "    \n",
    "    return lik0/lik1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "(100, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.8139424056348226"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n=10\n",
    "approx_bayesfactor(X, X1, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "bic0 = lik_mc(X, top_n)\n",
    "bic1 = lik_mc(X1, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3347493070415709e-07"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bic0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7128390743999501e-08"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
