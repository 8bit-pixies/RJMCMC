{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design idea:\n",
    "\n",
    "A graph can represent the pipeline. \n",
    "\n",
    "1.  Build the pipeline naively\n",
    "2.  Rearrange the order of the pipeline by the distance to `root` node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hinge import Hinge, error_on_split, error_on_split_reg\n",
    "from interaction import Interaction\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# using svm as per scikit-feature repo\n",
    "from sklearn.decomposition import FactorAnalysis # we shall use factor analysis to fix the size of final modelling ds.\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# for sampling\n",
    "import random # use random.choice? and random.sample for interactions\n",
    "\n",
    "# use networkx to keep track of changes to our data, so we can recreate things...\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from graph_utils import *\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Girth</th>\n",
       "      <th>Height</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.7</td>\n",
       "      <td>81.0</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Girth  Height  Volume\n",
       "0    8.3    70.0    10.3\n",
       "1    8.6    65.0    10.3\n",
       "2    8.8    63.0    10.2\n",
       "3   10.5    72.0    16.4\n",
       "4   10.7    81.0    18.8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # for making sure and exploring created datasets...\n",
    "X_df = pd.read_csv(\"trees.csv\")\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Girth', 'Height', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_df['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.drop(\"Volume\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_pipeline(additional_feats=[], X=X_df, y=y, verbose=True):\n",
    "    #print(additional_feats)\n",
    "    \n",
    "    pipeline = additional_feats[:]\n",
    "    \n",
    "    total_vars = len(pipeline) + len(X_df.columns)\n",
    "    dim_factor = max(min(total_vars, 20), len(X_df.columns))\n",
    "    \n",
    "    pipeline.append(('factor analysis', FactorAnalysis(dim_factor)))\n",
    "    pipeline.append(('linear reg', LinearRegression()))\n",
    "    model = Pipeline(pipeline[:])\n",
    "\n",
    "    # split data into 10 folds\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    results = cross_val_score(model, X, y, cv=kfold)\n",
    "    if verbose:\n",
    "        print(\"mse: {}\".format(results.mean()))\n",
    "    return results.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.6344963939498967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.63449639394989665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline solution - vanilla pipeline\n",
    "eval_pipeline(X=X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Search\n",
    "=======\n",
    "\n",
    "We have 4 possible situations:\n",
    "\n",
    "1. Grow - split : assumption is we always grow 2\n",
    "2. Grow - interaction\n",
    "3. Remove - split : assumption is we always destroy both\n",
    "4. Remove - interaction\n",
    "\n",
    "Proposal Distributions\n",
    "------------------------\n",
    "\n",
    "Assume each action has equal probability and is uniform.\n",
    "\n",
    "Then each proposal is simply:\n",
    "\n",
    "$$P(x^*|x^{(t)}) = \\frac{1}{\\text{num possible actions}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "In this setting there is no need for RJMCMC (yet) as the transformations are parameter free.\n",
    "\n",
    "What this means is we can do a straight MH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graph details...\n",
    "\n",
    "hinge parents will have attribute name hinge_children with value equal to the node name of the children\n",
    "interaction parents will have attribute name interaction_children with value equal to list of all nodes that are children\n",
    "\"\"\"\n",
    "\n",
    "# generate the base graph, where we have a the root node and all the base features...\n",
    "G=nx.DiGraph()\n",
    "G.add_node(\"root\")\n",
    "\n",
    "for col in X_df.columns:\n",
    "    # we can add node attributes, eg\n",
    "    #G.add_node(col, attribute='here')\n",
    "    G.add_node(col)\n",
    "    G.add_edge(\"root\", col)\n",
    "\n",
    "# add attribute to node base_0\n",
    "#G = set_graph_node_attributes(G, 'base_0', {'hinge_children': ['a', 'b']})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edges': [['root', 'Height', {}], ['root', 'Girth', {}]],\n",
       " 'nodes': [['root', {}], ['Height', {}], ['Girth', {}]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_to_dict(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_nodes_by_attribute(G, attri_key):\n",
    "    g_nodes_attr = graph_to_dict(G)['nodes']\n",
    "    g_nodes = [node for node, attr in g_nodes_attr if attri_key in attr.keys()]\n",
    "    return g_nodes\n",
    "\n",
    "def get_graph_attributes_by_key(G, attri_key):\n",
    "    g_nodes_attr = graph_to_dict(G)['nodes']\n",
    "    attr_values = [attri.get(attri_key, None) for _, attri in g_nodes_attr]\n",
    "    attr_values = [x for x in attr_values if x is not None]\n",
    "    return attr_values\n",
    "\n",
    "def get_all_node_attributes(G, node):\n",
    "    return G[node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_graph_node_attributes(G1, node, attri_dict):\n",
    "    \"\"\"\n",
    "    G is a networkx graph...\n",
    "    \"\"\"\n",
    "    G = G1.copy()\n",
    "    \n",
    "    #dict_items = attri_dict.items()    \n",
    "    for attri_name, attri_value in attri_dict.items():\n",
    "        nx.set_node_attributes(G, attri_name, {node: attri_value})\n",
    "    return G.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Migrate this to another module in the future\n",
    "\n",
    "Details\n",
    "-------\n",
    "\n",
    "### hinge\n",
    "\n",
    "**parent node**\n",
    "\n",
    "Will have details of the children in \"hinge_children\". \n",
    "That is...\n",
    "\n",
    "```\n",
    "Hinge(mask=parent)\n",
    "```\n",
    "\n",
    "A parent node will create two children\n",
    "\n",
    "pos_name = \"{}_poshinge\".format(remove_node_name)\n",
    "neg_name = \"{}_neghinge\".format(remove_node_name)\n",
    "\n",
    "### interaction\n",
    "\n",
    "**child node**\n",
    "\n",
    "Will have details of the parent in \"interaction_parent\"\n",
    "That is...\n",
    "\n",
    "```\n",
    "Interaction(['interaction1', 'interaction2'])\n",
    "```\n",
    "\n",
    "the node created will be the name\n",
    "\n",
    "\"{}_{}\".format(inter1, inter2)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_remove_hinge_candidates(G):\n",
    "    # get all nodes with attribute \"hinge_children\"\n",
    "    # where their totol children is 2 or less.    \n",
    "    hinge_parents = get_all_nodes_by_attribute(G, 'hinge_children')\n",
    "    \n",
    "    # now check that all hinge parents have 2 or less children...\n",
    "    hinge_parents = [parent for parent in hinge_parents if len(nx.descendants(G, parent)) <= 2]\n",
    "    return hinge_parents\n",
    "\n",
    "def get_grow_hinge_candidates(G):\n",
    "    # these are all nodes who do not have a hinge children attribute. \n",
    "    hinge_parents = get_all_nodes_by_attribute(G, 'hinge_children')\n",
    "    hinge_candidates = [node for node in G.nodes() if node not in hinge_parents and node != \"root\"]\n",
    "    return hinge_candidates\n",
    "\n",
    "def get_remove_interact_candidates(G):\n",
    "    # get all nodes with attribute \"interaction_parent\"\n",
    "    # where they have no children\n",
    "    interaction_nodes = get_all_nodes_by_attribute(G, 'interaction_parent')\n",
    "    # now check that all hinge parents have 2 or less children...\n",
    "    nodes = [node for node in interaction_nodes if len(nx.descendants(G, node)) == 0]\n",
    "    return nodes\n",
    "    \n",
    "def get_grow_interact_candidates(G):\n",
    "    # get all pairwise nodes which are not currently a pair?\n",
    "    all_nodes = G.nodes()\n",
    "    all_nodes = [x for x in all_nodes if x != \"root\"]\n",
    "    \n",
    "    # generate all pairs...\n",
    "    pairwise = itertools.combinations(all_nodes, 2)\n",
    "    itself = zip(*[all_nodes, all_nodes])\n",
    "    all_pairs = list(pairwise) + list(itself)\n",
    "    \n",
    "    seen_pairs = get_graph_attributes_by_key(G, 'hinge_children')\n",
    "    seen_pairs = [set([x,y]) for x,y in seen_pairs]\n",
    "    # remove \"seen\" pairs.\n",
    "    filter_pairs = [set([x,y]) for x,y in all_pairs if set([x,y]) not in seen_pairs]\n",
    "    return filter_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grow', 'hinge'), ('grow', 'interact')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# begin trying stuff\n",
    "# start simulations!\n",
    "def spawn_possible_actions(G):\n",
    "    actions = []\n",
    "    if get_remove_interact_candidates(G):\n",
    "        actions.append((\"remove\", \"interact\"))\n",
    "    if get_remove_hinge_candidates(G):\n",
    "        actions.append((\"remove\", \"hinge\"))\n",
    "    if get_grow_hinge_candidates(G):\n",
    "        actions.append((\"grow\", \"hinge\"))\n",
    "    if get_grow_interact_candidates(G):\n",
    "        actions.append((\"grow\", \"interact\"))\n",
    "    return actions\n",
    "\n",
    "spawn_possible_actions(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spawn_action_candidates(G, action, transform):\n",
    "    if action == 'grow':\n",
    "        if transform == 'hinge':\n",
    "            return get_grow_hinge_candidates(G)\n",
    "        elif transform == 'interact':\n",
    "            return get_grow_interact_candidates(G)\n",
    "        else:\n",
    "            raise Exception(\"invalid transform function\")\n",
    "    if action == 'remove':\n",
    "        if transform == 'hinge':\n",
    "            return get_remove_hinge_candidates(G)\n",
    "        elif transform == 'interact':\n",
    "            return get_remove_interact_candidates(G)\n",
    "        else:\n",
    "            raise Exception(\"invalid transform function\")\n",
    "    else:\n",
    "        raise Exception(\"invalid grow function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spawn_new_model(G):\n",
    "    # to spawn a model, spawn possible actions:    \n",
    "    all_actions = spawn_possible_actions(G)\n",
    "    action, transform = random.choice(all_actions)\n",
    "    # this just returns the function that is randomly chosen.\n",
    "    candidates = spawn_action_candidates(G, action, transform)\n",
    "    selected_node = random.choice(candidates)\n",
    "    return {'action': action, \n",
    "            'transform': transform,\n",
    "            'selected_node': selected_node}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spawn_new_pipeline(G, mode=\"classification\"):\n",
    "    \"\"\"\n",
    "    Take in a networkx graph as a dictionary object\n",
    "    \n",
    "    We will convert a graph to pipeline objects,\n",
    "    and then reorder based on distance to root node. \n",
    "    \n",
    "    Usage for shortest path: \n",
    "    print(nx.shortest_path_length(G,source=0,target=4))\n",
    "    \n",
    "    hopefully this works...\n",
    "    \"\"\"\n",
    "    # just randomly add...pipeline transformations   \n",
    "    g_nodes = graph_to_dict(G)['nodes']\n",
    "    \n",
    "    # add all hinge nodes...\n",
    "    if mode == \"classification\":\n",
    "        hinge_info = [(\"hinge_{}\".format(node), Hinge(mask=node, psplit=error_on_split), node,\n",
    "                  nx.shortest_path_length(G,source=\"root\",target=node)) \n",
    "                  for node, attr in g_nodes if 'hinge_children' in attr.keys()]\n",
    "    else: \n",
    "        hinge_info = [(\"hinge_{}\".format(node), Hinge(mask=node, psplit=error_on_split_reg), node,\n",
    "                  nx.shortest_path_length(G,source=\"root\",target=node)) \n",
    "                  for node, attr in g_nodes if 'hinge_children' in attr.keys()]\n",
    "    \n",
    "    \n",
    "    # add all interaction nodes...\n",
    "    # length + 1 as interaction thing is at parent level? when we consider things\n",
    "    # like removal\n",
    "    interact_info = [(\"interact_{}\".format('_'.join(attr['interaction_parent'])), \n",
    "                      Interaction(attr['interaction_parent']), \n",
    "                      node, \n",
    "                      nx.shortest_path_length(G,source=\"root\",target=node)+1)\n",
    "                     for node, attr in g_nodes if 'interaction_parent' in attr.keys()]\n",
    "    \n",
    "    \n",
    "    # join all together\n",
    "    pipeline = hinge_info + interact_info\n",
    "    \n",
    "    # sort the pipeline by location of node to root...\n",
    "    pipeline.sort(key=lambda x: x[3])\n",
    "    #print(pipeline)\n",
    "    # remove last element in pipeline..\n",
    "    pipeline = [(x, y) for x,y,_,_ in pipeline]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen action/transform: grow interact\n",
      "selected node(s): {'Girth'}\n"
     ]
    }
   ],
   "source": [
    "### spawn one pass...\n",
    "new_model = spawn_new_model(G)\n",
    "print(\"Chosen action/transform: {} {}\".format(new_model['action'], new_model['transform']))\n",
    "print(\"selected node(s): {}\".format(new_model['selected_node']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _proposal(G, action, transform):\n",
    "    \"\"\"\n",
    "    G is current graph of model.\n",
    "    \n",
    "    return proportional probabilities related to proposal distributions,\n",
    "    both the current proposal and the \"proposed\" proposal\n",
    "    \n",
    "    x*|xt is proposal prime\n",
    "    xt|x* is proposal cur\n",
    "    \n",
    "    available transforms:\n",
    "    if get_remove_interact_candidates(G):\n",
    "    if get_remove_hinge_candidates(G):\n",
    "    if get_grow_hinge_candidates(G):\n",
    "    if get_grow_interact_candidates(G):\n",
    "\n",
    "    use this: simulate_new_graph\n",
    "\n",
    "    \"\"\"\n",
    "    if action == \"remove\" and transform == \"interact\":\n",
    "        all_pos_parents = get_remove_interact_candidates(G)\n",
    "        proposal_prime = 1.0/len(all_pos_parents)\n",
    "        \n",
    "        # simulate removing a pair...\n",
    "        all_interact_nodes = graph_to_dict(G.copy())['nodes']\n",
    "        all_interact_nodes = [node for node, attr in all_interact_nodes if 'interaction_parent' in attr.keys()]\n",
    "        \n",
    "        G_prime = simulate_new_graph(G.copy(), {\n",
    "            'action': action, 'transform': transform, 'selected_node': all_interact_nodes[0]\n",
    "        })\n",
    "        \n",
    "        proposal_cur = 1.0/len(get_grow_interact_candidates(G_prime))\n",
    "        \n",
    "    if action == \"remove\" and transform == \"hinge\":\n",
    "        all_pos_parents = get_remove_hinge_candidates(G)\n",
    "        proposal_prime = 1.0/len(all_pos_parents)\n",
    "        \n",
    "        # simulate removing a pair\n",
    "        G_prime = G.copy()\n",
    "        remove_node_name = all_pos_parents[0]\n",
    "        pos_name = \"{}_poshinge\".format(remove_node_name)\n",
    "        neg_name = \"{}_neghinge\".format(remove_node_name)\n",
    "        G_prime.remove_node(pos_name)\n",
    "        G_prime.remove_node(neg_name)\n",
    "        proposal_cur = 1.0/len(get_grow_hinge_candidates(G_prime))\n",
    "        \n",
    "                \n",
    "    if action == \"grow\" and transform == \"hinge\":\n",
    "        all_pos_candidates = get_grow_hinge_candidates(G)\n",
    "        proposal_prime = 1.0/len(all_pos_candidates)\n",
    "        \n",
    "        # simulate adding a random proposal\n",
    "        G_prime = G.copy()\n",
    "        add_node_name = all_pos_candidates[0]\n",
    "        pos_name = \"{}_poshinge\".format(add_node_name)\n",
    "        neg_name = \"{}_neghinge\".format(add_node_name)\n",
    "        \n",
    "        # add...\n",
    "        G_prime.add_node(pos_name, hinge='', hinge_parent=add_node_name)\n",
    "        G_prime.add_node(neg_name, hinge='', hinge_parent=add_node_name)\n",
    "        G_prime.add_edge(add_node_name, pos_name)\n",
    "        G_prime.add_edge(add_node_name, neg_name)\n",
    "        \n",
    "        proposal_cur = 1.0/len(get_remove_hinge_candidates(G_prime))\n",
    "        \n",
    "    if action == \"grow\" and transform == \"interact\":\n",
    "        all_pos_candidates = get_grow_interact_candidates(G)\n",
    "        proposal_prime = 1.0/len(all_pos_candidates)\n",
    "\n",
    "        # simulate adding a random proposal\n",
    "        G_prime = G.copy()\n",
    "        \n",
    "        # interaction\n",
    "        G_prime = G.copy()\n",
    "        add_node_name = list(all_pos_candidates[0])\n",
    "        if len(add_node_name) == 1:\n",
    "            add_node_name = add_node_name[:] + add_node_name[:]\n",
    "        interact_name = \"{}_{}\".format(add_node_name[0], add_node_name[1])\n",
    "        \n",
    "        # add...\n",
    "        G_prime.add_node(interact_name, interaction=[add_node_name[0], add_node_name[1]])\n",
    "        G_prime.add_edge(add_node_name[0], interact_name)\n",
    "        G_prime.add_edge(add_node_name[1], interact_name)\n",
    "        \n",
    "        proposal_cur = 1.0/len(get_remove_interact_candidates(G_prime))\n",
    "    \n",
    "    # add fudge scaling factor\n",
    "    proposal_cur = min(proposal_cur, 0.25)\n",
    "    proposal_prime = min(proposal_prime, 0.25)\n",
    "    \n",
    "    return proposal_cur, proposal_prime\n",
    "    \n",
    "def proposal(G, action, transform):\n",
    "    try: \n",
    "        proposal_cur, proposal_prime = _proposal(G, action, transform)\n",
    "        return proposal_cur, proposal_prime\n",
    "    except ZeroDivisionError as err:\n",
    "        print(\"Warning: Move appears to be invalid\")\n",
    "        return 1.0, 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _acceptance(proba_cur, proba_prime, proposal_cur, proposal_prime):\n",
    "    accept = (proba_prime/proba_cur) * (proposal_cur/proposal_prime)\n",
    "    return min(1.0, accept)\n",
    "\n",
    "def propose_iter(G_dict, mode=\"regression\"):\n",
    "    \"\"\"\n",
    "    Takes in list of graphs as dict objects    \n",
    "    \"\"\"\n",
    "    last_model = G_dict.copy()\n",
    "    #print(last_model )\n",
    "    curr_G = dict_to_graph(last_model)\n",
    "    propose_model = spawn_new_model(dict_to_graph(last_model)) # provide the action/transform pair\n",
    "    proposed_graph = simulate_new_graph(curr_G, propose_model)\n",
    "    curr_pipeline = spawn_new_pipeline(curr_G, mode=mode) # maybe rename to spawn_pipeline\n",
    "    propose_pipeline = spawn_new_pipeline(dict_to_graph(proposed_graph), mode=mode)\n",
    "    \n",
    "    #print(propose_pipeline)\n",
    "    #print(curr_pipeline)\n",
    "    proba_cur = eval_pipeline(additional_feats=curr_pipeline, X=X_df, verbose=False)\n",
    "    #print(propose_pipeline)\n",
    "    proba_prime = eval_pipeline(additional_feats=propose_pipeline, X=X_df, verbose=False)\n",
    "    \n",
    "    proposal_cur, proposal_prime = proposal(curr_G, propose_model['action'], propose_model['transform'])\n",
    "    \n",
    "    result = {'acceptance_proba': _acceptance(proba_cur, proba_prime, proposal_cur, proposal_prime)}\n",
    "    \n",
    "    result_new = result.copy()\n",
    "    result_new.update(propose_model)\n",
    "    result['proposed_graph'] = curr_G.copy\n",
    "    return result_new\n",
    "\n",
    "# if proposal is accepted...update G and transform list here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_new_graph(G_new, proposed):\n",
    "    \"\"\"\n",
    "    G_new is a graph\n",
    "    proposed is a dict like this: {'action': 'grow', 'selected_node': 'base_12', 'transform': 'hinge'}\n",
    "    \n",
    "    return a graph as a dict obj\n",
    "    \n",
    "    \"\"\"\n",
    "    #G_new = dict_to_graph(G_list[-1].copy())    \n",
    "    \n",
    "    # now in G, we add or remove as needed...\n",
    "    if proposed['action'] == 'grow':\n",
    "        if proposed['transform'] == 'hinge':\n",
    "            #print(proposed['selected_node'])\n",
    "            pos_name = \"{}_poshinge\".format(proposed['selected_node'])\n",
    "            neg_name = \"{}_neghinge\".format(proposed['selected_node'])\n",
    "            G_new.add_node(pos_name)\n",
    "            G_new.add_node(neg_name)\n",
    "            G_new.add_edge(proposed['selected_node'], pos_name)\n",
    "            G_new.add_edge(proposed['selected_node'], neg_name)\n",
    "            \n",
    "            # add attributes, which is to the parent node.\n",
    "            attributes = get_all_node_attributes(G_new, proposed['selected_node']).copy()\n",
    "            attributes['hinge_children'] = [pos_name, neg_name]\n",
    "            G_new = set_graph_node_attributes(G_new, proposed['selected_node'], attributes)\n",
    "            \n",
    "        elif proposed['transform'] == 'interact':\n",
    "            inter_nodes = list(proposed['selected_node'])\n",
    "            #print(inter_nodes)\n",
    "            if len(inter_nodes) == 1:\n",
    "                inter_nodes = inter_nodes[:] + inter_nodes[:]\n",
    "            interact_name = \"{}_{}\".format(inter_nodes[0], inter_nodes[1])\n",
    "            G_new.add_node(interact_name)\n",
    "            G_new.add_edge(inter_nodes[0], interact_name)\n",
    "            G_new.add_edge(inter_nodes[1], interact_name)\n",
    "            \n",
    "            # add attributes, which is on the child node\n",
    "            attributes = get_all_node_attributes(G_new, interact_name).copy()\n",
    "            attributes['interaction_parent'] = [inter_nodes[0], inter_nodes[1]]\n",
    "            G_new = set_graph_node_attributes(G_new, interact_name, attributes)\n",
    "        else:\n",
    "            raise Exception(\"action/transform pair: {} {} appears to be invalid\".format(proposed['action'], proposed['transform']))\n",
    "    elif proposed['action'] == 'remove':        \n",
    "        if proposed['transform'] == 'hinge':\n",
    "            #print(\"\\tremove all child nodes of node {}\".format(proposed['selected_node']))            \n",
    "            all_children = nx.descendants(G, proposed['selected_node'])\n",
    "            for node in all_children:\n",
    "                G_new.remove_node(node)\n",
    "        elif proposed['transform'] == 'interact':\n",
    "            #print(\"\\tremove interact node {}\".format(proposed['selected_node']))\n",
    "            G_new.remove_node(proposed['selected_node'])\n",
    "        else:\n",
    "            raise Exception(\"action/transform pair: {} {} appears to be invalid\".format(proposed['action'], proposed['transform']))    \n",
    "    else:\n",
    "        raise Exception(\"action/transform pair: {} {} appears to be invalid\".format(proposed['action'], proposed['transform']))\n",
    "    return graph_to_dict(G_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_iter(G_list, proposed):\n",
    "    G_last = dict_to_graph(G_list[-1].copy())    \n",
    "    G_new_dict = simulate_new_graph(G_last, proposed)\n",
    "    \n",
    "    # add things...\n",
    "    G_new_list = G_list[:]\n",
    "    G_new_list.append(G_new_dict)\n",
    "    return G_new_list[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mh_iter(G_list):\n",
    "    u = np.random.uniform()    \n",
    "    proposed = propose_iter(G_list[-1])\n",
    "    \n",
    "    # make u =0 .\n",
    "    print(proposed['acceptance_proba'])\n",
    "    if u < proposed['acceptance_proba']:\n",
    "        #print(proposed)\n",
    "        return create_iter(G_list, proposed)\n",
    "    else:\n",
    "        print(\"repeat previous\\n\\t\")\n",
    "        #print(proposed)\n",
    "        # repeat the previous one...\n",
    "        return G_list[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate the base graph, where we have a the root node and all the base features...\n",
    "G=nx.DiGraph()\n",
    "G.add_node(\"root\")\n",
    "\n",
    "for col in X_df.columns:\n",
    "    # we can add node attributes, eg\n",
    "    #G.add_node(col, attribute='here')\n",
    "    G.add_node(col)\n",
    "    G.add_edge(\"root\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Warning: Move appears to be invalid\n",
      "repeat previous\n",
      "\t\n",
      "Performance at pipeline: [] is \n",
      "\t-0.3226561682659085\n",
      "\n",
      "1\n",
      "Warning: Move appears to be invalid\n",
      "Performance at pipeline: ['interact_Girth_Girth'] is \n",
      "\t0.7998745295059566\n",
      "\n",
      "2\n",
      "Warning: Move appears to be invalid\n",
      "repeat previous\n",
      "\t\n",
      "Performance at pipeline: ['interact_Girth_Girth'] is \n",
      "\t0.8270663174999051\n",
      "\n",
      "3\n",
      "Warning: Move appears to be invalid\n",
      "repeat previous\n",
      "\t\n",
      "Performance at pipeline: ['interact_Girth_Girth'] is \n",
      "\t0.907490130045724\n",
      "\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Girth_Girth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2133\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2134\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13742)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13696)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Girth_Girth'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-9191ac156985>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mG_list_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmh_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mG_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG_list_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-a69f07c70784>\u001b[0m in \u001b[0;36mmh_iter\u001b[1;34m(G_list)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmh_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mproposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpropose_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# make u =0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-19075f67f642>\u001b[0m in \u001b[0;36mpropose_iter\u001b[1;34m(G_dict, mode)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mproba_cur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madditional_feats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#print(propose_pipeline)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mproba_prime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madditional_feats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpropose_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mproposal_cur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproposal_prime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproposal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_G\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpropose_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'action'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpropose_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-8a46040e21d7>\u001b[0m in \u001b[0;36meval_pipeline\u001b[1;34m(additional_feats, X, y, verbose)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# split data into 10 folds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mse: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\chapm\\Documents\\GitHub\\RJMCMC\\autorj\\hinge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \"\"\"\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2057\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2064\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1386\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3542\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3543\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3544\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chapm\\anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2134\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2136\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13742)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13696)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Girth_Girth'"
     ]
    }
   ],
   "source": [
    "iters = 10\n",
    "\n",
    "G_list = [graph_to_dict(G)]\n",
    "\n",
    "for i in range(iters):\n",
    "    print(i)\n",
    "    G_list_temp = mh_iter(G_list[:])\n",
    "    G_list = G_list_temp[:]\n",
    "    \n",
    "    if i % 1 == 0:\n",
    "        pipeline = G_list[-1]\n",
    "        check_pipeline = spawn_new_pipeline(dict_to_graph(pipeline))\n",
    "        human_readable_pipeline = [x for x, y in check_pipeline]\n",
    "        #print(\"Evaluating pipeline: {}\".format(spawn_pipeline))\n",
    "        perf = eval_pipeline(additional_feats=check_pipeline, X=X_df, verbose=False)\n",
    "        print(\"Performance at pipeline: {} is \\n\\t{}\\n\".format(human_readable_pipeline, perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposed model in R is...\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "b = (2.3-a)**2\n",
    "np.hstack([b,b])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
